{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Spam Classifier\n",
    "![the essense](https://miro.medium.com/max/1627/1*0IPNc3rz6eIpBSiTKNzvFQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config:\n",
    "### Setting consts, variables, utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data_url = '../input/spam-or-not-spam-dataset/spam_or_not_spam.csv'\n",
    "\n",
    "pA = 0  # probability of encountering SPAM\n",
    "pNotA = 0  # probability of encountering NOT SPAM\n",
    "\n",
    "## Consts\n",
    "SPAM = 1\n",
    "NOT_SPAM = 0\n",
    "WORD_MIN_LENGTH = 3  # minimum separate word length to consider it valuable for model training\n",
    "\n",
    "## Vars\n",
    "trainPositive, trainNegative = {}, {}  # dictionaries for storing quantities of spam / non-spam words.\n",
    "unique_words = 0  # number of unique words in general\n",
    "totals = [0, 0]  # total amounts of non-spam [0] / spam [1] words\n",
    "\n",
    "## Helper func to easily retrieve required dictionary by label\n",
    "get_dict = lambda label: trainPositive if label == SPAM else trainNegative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Making model train functions ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main model training func:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_df):\n",
    "    spam_count = 0\n",
    "    total = len(train_df)\n",
    "    for i in range(total):\n",
    "        row = train_df.iloc[i]\n",
    "        calculate_word_frequencies(row.email, row.label)\n",
    "        spam_count += row.label\n",
    "    global pA, pNotA, unique_words\n",
    "    unique_words = len({*trainPositive, *trainNegative})\n",
    "    pA = spam_count / total\n",
    "    pNotA = 1 - pA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to train the model correctly, we need to calculate words encountering frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_frequencies(body, label):\n",
    "    wordsDict = get_dict(label)\n",
    "    for word in make_training_sample(body):\n",
    "        wordsDict[word] = wordsDict.get(word, 0) + 1\n",
    "        totals[label] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following functions will help us cleanse and prepare text data for training / classifying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_sample(text):\n",
    "    s = re.sub('NUMBER', ' NUMBER ', text)\n",
    "    words = []\n",
    "    for w in re.findall(r'[a-zA-Zа-яА-ЯёЁ]+', s):  # get only words consisting of letters\n",
    "        if len(w) >= WORD_MIN_LENGTH:  # satisfy the minimum valuable length of a word\n",
    "            if w not in ['NUMBER', 'URL']:  # words NUMBER and URL are considered special masks\n",
    "                w = w.lower()\n",
    "            words.append(w)\n",
    "    return words\n",
    "\n",
    "def generalize_email(text):\n",
    "    t = text.lower()\n",
    "    t = re.sub(r'\\d+[,.]{1}', lambda m: m.group()[:-1], t)  # bring digital numbers to general form\n",
    "    t = re.sub(r'\\d+', ' NUMBER ', t)  # replace all digital numbers with word 'NUMBER'\n",
    "    t = re.sub(r'[^a-zA-Zа-яА-ЯёЁ]+', ' ', t)  # replace all non-letter characters with spaces\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, let's implement the Naive Bayes Classifier formulas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(Bi|A) - probability of finding word among SPAM (A) / NOT SPAM (^A)\n",
    "def calculate_P_Bi_A(word, label):\n",
    "    return (get_dict(label).get(word, 0) + 1) / (unique_words + totals[label])\n",
    "    \n",
    "# P(B|A) - probability of encountering text among SPAM (A) / NOT SPAM (^A)\n",
    "def calculate_P_B_A(body, label):\n",
    "    return sum([math.log(calculate_P_Bi_A(word, label)) for word in body.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ..as well as the main func to classify email as SPAM / NOT SPAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(email):\n",
    "    if 0 in totals:\n",
    "        return 'ERROR: Not enough train data or model training failed!'\n",
    "    email = generalize_email(email)\n",
    "    isSpam = math.log(pA) + calculate_P_B_A(email, SPAM)\n",
    "    isNotSpam = math.log(pNotA) + calculate_P_B_A(email, NOT_SPAM)\n",
    "    spam_prob = 1 / (1 + math.exp(isNotSpam - isSpam))\n",
    "    return ('SPAM' if isSpam > isNotSpam else 'NOT SPAM') + f' ::: Spam Probability: {str(spam_prob * 100)[0:6]} %'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_url)\n",
    "df = df.dropna()\n",
    "\n",
    "train(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example1: SPAM ::: Spam Probability: 100.0 %\n",
      "example2: NOT SPAM ::: Spam Probability: 0.0002 %\n",
      "example3: SPAM ::: Spam Probability: 99.999 %\n",
      "\n",
      "pA: 0.1663887962654218\n",
      "total words: [431256, 159253]\n",
      "unique words: 38950\n",
      "unique NOT_SPAM Dict words: 24225 \n",
      "unique SPAM Dict words: 21123\n"
     ]
    }
   ],
   "source": [
    "example1 = '''\n",
    "Hi, My name is Warren E. Buffett an American business magnate, investor and philanthropist. \n",
    "am the most successful investor in the world. I believe strongly in‘giving while living’ \n",
    "I had one idea that never changed in my mind? that you should use your wealth to help people \n",
    "and i have decided to give {$1,500,000.00} One Million Five Hundred Thousand United Dollars, \n",
    "to randomly selected individuals worldwide. On receipt of this email, you should count yourself \n",
    "as the lucky individual. Your email address was chosen online while searching at random. \n",
    "Kindly get back to me at your earliest convenience before i travel to japan for my treatment , \n",
    "so I know your email address is valid. Thank you for accepting our offer, we are indeed grateful \n",
    "You Can Google my name for more information: God bless you. Best Regard Mr.Warren E. Buffett \n",
    "Billionaire investor !\n",
    "'''\n",
    "\n",
    "example2 = '''\n",
    "Hi guys I want to build a website like REDACTED and I wanted to get your perspective of \n",
    "whether that site is good from the users' perspective before I go ahead and build something \n",
    "similar. I think that the design of the site is very modern and nice but I am not sure how \n",
    "people would react to a similar site? I look forward to your feedback. Many thanks!\n",
    "'''\n",
    "\n",
    "example3 = '''\n",
    "As a result of your application for the position of Data Engineer, I would like to invite \n",
    "you to attend an interview on May 30, at 9 a.m. at our office in Washington, DC. You will \n",
    "have an interview with the department manager, Moris Peterson. The interview will last \n",
    "about 45 minutes. If the date or time of the interview is inconvenient, please contact me \n",
    "by phone or email to arrange another appointment. We look forward to seeing you.\n",
    "'''\n",
    "\n",
    "print('example1:', classify(example1))\n",
    "print('example2:', classify(example2))\n",
    "print('example3:', classify(example3))\n",
    "\n",
    "print('\\n'f'pA: {pA}')\n",
    "print(f'total words: {totals}')\n",
    "print(f'unique words: {unique_words}')\n",
    "print('unique NOT_SPAM Dict words:', len(trainNegative), '\\nunique SPAM Dict words:', len(trainPositive))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
